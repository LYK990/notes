# 计算机组成原理

## CPU

# 计算机操作系统

## 内存

内存是存放数据的硬件。程序执行前需要先放到内存中才能被CPU处理。

平时各种各样的软件都是存储在外存中的，电脑中的外存指的硬盘，硬盘是一种慢速的设备，而内存是一种超快速的设备。将需要运行的各种各样的软件都放到内存里，cpu直接从内存中存取这些设备。

内存分为内存地址和存储单元，每个内存地址对应一个存储单元。内存的存储大小要看是按字节还是按字编址，如果计算机**按字节编址**，每个存储单元大小为1字节（1B），如果字长为16位的计算机**按字编址**，则每个存储单元大小为1个字，每个字的大小为16个二进制位。

（进程由三个部分组成，程序段、数据端还有PCB），写的代码经过编译之后会形成对应的机器指令，而这些指令会放在内存中，cpu根据内存中程序段中一系列的指令来完成事情，

编译其实就是把高级语言编译成机器语言，编译程序会将用户的源代码编译成多个目标模块，，由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一整个的装入模块，再由装入程序将装入模块装入内存中运行。

内存不够时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘空间动态调度）。

（单一连续分配）

（固定分区分配）为了能在内存中装入多道程序，且这些程序不会相互干扰，于是就将内存分配成了多个分区，在每个分区中只装入一道作业。操作系统建立了一个分区说明表，来实现各个分区的分配和回收。每个表项包括分区的大小、起始地址、状态（是否已分配）。当用户要装入内存的时候，操作系统就会根据分区说明表，从其中找到一个满足大小未分配的分区，分配给该程序，然后修改状态为已分配。

（动态分区分配）在进程装入内存的时候，根据进程的大小动态的创建分区。使分区的大小正好适合进程的需要，这种分配方式会建立一个空闲分区表，表项 中包含分区号、 分区大小、分区 起始地址等信息。

在一开始给多个进程分配分区时，这些进程在内存中是紧挨着的，随着多次回收和分配，进程在内存中会变成离散分布，并可能出现大量外部碎片。动态分区不会产生内部碎片，因为每个分区大小都等于该进程所需内存大小。

此时可以用**紧凑**技术解决，将离散的进程变成在内存中紧密相连，**紧缩是指将所有进程占用的分区移动到一端使其紧凑的挨在一起，空闲区留在另一端**。

## 栈和堆的区别

cpu中有个核心模块叫ALU,专门用来做逻辑运算，如果算式比较复杂，没法一次性算出结果，会先计算，得到一个临时结果，这就需要将临时结果找个地方存放一下，这个玩意就叫寄存器。

为了降低cpu设计的复杂性以及成本，但同时又为了实现更复杂的计算，需要在内存中划分一个专门的区域用来存放临时数据。

栈和堆本质上都只是内存中的一片区域。从栈中取出数据的时候会先复制到cpu中的寄存器，出栈时这个数据还在堆栈里，但是已经被当作垃圾了。

在多线程环境下每一个线程都可以有他自己完全的独立的栈，但是他们共享堆。并行存取被堆控制而不是栈

**栈:**

1. 和堆一样存储在计算机 RAM 中。
2. 在栈上创建变量的时候会扩展，并且会自动回收。
3. 相比堆而言在栈上分配要快的多。
4. 用数据结构中的栈实现。
5. 存储局部数据，返回地址，用做参数传递。
6. 当用栈过多时可导致栈溢出（无穷次（大量的）的递归调用，或者大量的内存分配）。
7. 在栈上的数据可以直接访问（不是非要使用指针访问）。
8. 如果你在编译之前精确的知道你需要分配数据的大小并且不是太大的时候，可以使用栈。
9. 当你程序启动时决定栈的容量上限。

**堆：**

1. 和栈一样存储在计算机RAM。
2. 在堆上的变量必须要手动释放，不存在作用域的问题。数据可用 delete, delete[] 或者 free 来释放。
3. 相比在栈上分配内存要慢。
4. 通过程序按需分配。
5. 大量的分配和释放可造成内存碎片。
6. 在 C++ 中，在堆上创建数的据使用指针访问，用 new 或者 malloc 分配内存。
7. 如果申请的缓冲区过大的话，可能申请失败。
8. 在运行期间你不知道会需要多大的数据或者你需要分配大量的内存的时候，建议你使用堆。
9. 可能造成内存泄露。

进程的堆用于动态内存分配，即存放编译时大小未知的变量。和能够自动释放的栈不同，堆由用户进程自行管理，堆内的变量需要显式释放（free指令），否则该变量会一直存在于内存中，一直不释放会造成内存泄漏。

## 进程和线程

### 进程

早期计算机运行程序时只能一次运行一个程序，而且所有的系统资源（如CPU、内存和IO设备等）都由该程序单独使用，在该程序运行完之前其他程序无法运行，这就是单道程序设计。

**单道程序系统**的内存中除了操作系统这个内核程序之外，只有一个用户程序在内存中。其缺点时浪费资源且程序运行效率低。

**多道程序设计**允许内存中存放多道程序，它们在操作系统的调度下交替的在CPU上运行从而实现程序的并发，提高了程序执行的效率和资源利用率。

由于计算机中有多道程序，因此内存中保存了多个程序的程序段和数据段，操作系统如何才能找到各个程序程序段和数据段的位置？计算机里的设备分配给不同的程序，如何知道哪些设备被哪些程序占用？CPU运行一个程序A运行到一半就切换到另一个程序，程序A的CPU环境或者说它的运行状态和进度存放到哪里？

为此，操作系统为每一个要投入运行的程序设置了一个PCB（进程控制块）的结构来保存上述的程序控制信息。由此，也引出了进程的概念，多道程序设计中程序的并发执行就是通过进程实现的。

**进程是程序的一次执行过程，是系统进行资源分配和调度的单位**。

**一个进程实体（进程映像）由数据段、程序段和PCB三部分组成，它们离散的存储在内存中**。

PCB保存了所有操作系统管理和控制该进程所需的控制信息

进程分为几种状态

**运行状态**：当前进程已经分配到CPU的状态。处于这种状态的进程数不会大于计算机CPU的个数。

**就绪状态**：进程已具备运行条件和所有所需资源但唯独没有分配到CPU的状态，一旦CPU空闲，该进程就有机会获得CPU控制权进入运行状态。

**阻塞状态**：进程因等待某种事件而暂时不能运行的状态（如等待某个输入或输出、等待其他进程发来的信号等）。即使CPU空闲也无法获取其控制权。

**新建状态**：进程正在被创建，操作系统正为进程分配资源 和 初始化PCB的状态。

**终止状态**：进程完成自己任务正常终止或遇到错误被迫终止或人工干预终止时，操作系统正回收进程的资源，撤销PCB过程的状态。

### 线程

一个进程可能也需要同时处理多个任务，例如QQ软件可能要同时运行视频聊天的处理程序，也要运行传送文件程序。

为了满足这种需求，操作系统引入了线程，进程就不再是运行调度的最小单位，而只是资源分配的单位，线程变成了运行调度的最小单位（作为CPU的分配单元），同一个进程内的线程之间可以并发，不同进程之间（的线程）也可以并发

线程也有就绪、阻塞和运行这3种基本状态；

线程几乎不独立拥有系统资源，而是共享进程内的资源，但线程可以独立拥有CPU资源（一个进程内的多个线程可以在不同的CPU上并行运行证明线程可以拥有CPU资源）。

由于共享进程的内存空间，因此同一个进程中的线程间通信几乎无需系统干预；

切换同一进程的线程不会引起进程切换，开销很小；切换不同进程的线程会引起进程切换，开销大。

### 线程和进程关系

一个进程可以有多个线程，但至少要有一个线程；

一个线程只能在该进程的地址空间活动。

资源分配给进程，同一进程下的所有线程共享该进程所有资源。

同一进程中的多线程只能并发不能并行，因为他们只能运行在一个CPU上，用户程序在同一个进程时间片内切换多个线程

### 进程间关系

互斥：多个并发进程需要共享资源时，宏观或微观上一段时间内进程只能交替使用这个资源，而不能共享这个资源，我们称多个进程互斥访问资源。

同步：多个并发进程合作完成一个任务的过程中，不同进程的子任务是相互依赖的，让无序的进程（异步性）按指定顺序完成各自的任务从而完成整体任务就是同步。

## 操作系统中进程和线程怎么通信

## 进程通信的方式

- **共享内存**：共享内存是在内存分配一块空间作为多个通信进程的共享存储区，**需要通信的多个进程把共享存储区附加到自己的地址空间**就可以对共享存储区读写，多个进程对共享空间的访问是互斥的，通过操作系统提供的互斥工具实现互斥，因此进程间共享需要系统介入，
- **管道通信：**管道是用于连接读写进程的一个共享文件（又称pipe文件），其本质是OS在内存中开辟的一个大小固定的缓冲区（通常为一个内存页大小，约为4K）。读写进程可以通过该共享文件传递数据。
  -  管道采用半双工通信，某一时间段内只能实现单向传输
  - 写进程写的时候，读进程不能读，必须写完之后，写进程释放管道，读进程才能从管道读
  - 数据以字符流的形式写入管道。管道写满时，写进程执行write()系统调用会阻塞进程，直到管道有空间写入；管道读空时，读进程执行read()系统调用会阻塞进程，直到管道有数据到来；
  - 如果没写满，则不允许读；如果没读空，就不允许写
  - 数据一旦被读出，就会被管道抛弃
- **消息传递：**











# 计算机网络

## TCP三次握手和四次挥手

#### 三次握手

一个文件通常会被拆分为很多数据包来进行传输，而数据包在传输过程中又有很大概率丢失或者出错。TCP的头部包含源端口号、目的端口号、序列号等，TCP是传输层协议。全双工通信，三次握手是建立连接时的准备工作，其实就是把自身的序列号发送给对方（**syn~ack~ack**），看对方能不能收到。最开始服务器监听某个端口，客户端发送syn包，可以建立连接之后服务端返回syn+ack包，客户端再发送ack包。

tcp连接会建立一个发送缓冲区，第一个自己的序列号是0，后面的每个字节的序列号就会增加1，

- 发送数据时就会从发送缓冲区取一部分数据组成发送报文，在tcp协议头中会附带序列号和长度。
- 接受端在收到数据后需要回复确认报文，确认报文ack=接受序列号+长度，也就是下一包（**客户端**）需要发送的起始序列号
- 发送端可以发送一次连续的多包数据。接收端只需要回复一次ack就可以了。
- 这样发送端可以把一系列的数据切割成碎片发送给服务端
- 服务端根据序号和长度在接受后重构出来完整的数据
- 数据包丢失，客户端可以重传

#### 四次挥手

客户端和服务端都可以先发起关闭请求

- 客户端向服务端发起关闭请求，需要向服务端发送fin包，客户端禁止终止等待1状态， （第一次挥手）
- 服务端发送ack包，表示服务端进入了关闭等待状态
- 客户端进入终止等待2状态，（第二次挥手）
- 服务端发送fin包进入最后确认状态 （第三次挥手）
- 客户端收到之后回复ack包，进入超时等待状态（为了保证服务端收到ack包），经过超时时间之后关闭连接，而服务端收到ack包后立即关闭连接（第四次挥手）
- 超时等待是为了保证服务端已经收到ack包，假设客户端发送了最后一包ack包后就释放了连接，一旦ack包在网络中丢失，服务端将一直停留在最后确认状态。如果客户端发哦是那个最后一包ack包后，等待一段时间，这时服务端因为没有收到ack包，会 重发fin包。客户端会响应这个ack包并刷新超时时间。

#### TCP为什么不能两次握手

两次握手只能保证客户端的序列号成功被服务端接收，而服务端是无法确认自己的序列号是否被客户端成功接收。所以是不行的

第一次发送syn包时，如果丢了，客户端发第二次，服务端返回syn+ack，此时建立连接，但是如果第一次恢复了。服务端就会误以为又要建立连接了。此时客户端认为时两次连接，而服务端任务时一次连接，造成状态不一致。

第三次握手，如果客户段没有收到最后的syn包，就不回认为连接成功

## UDP和TCP的对比

只要在网络层使用ip协议，就可以接入到使用tcp/ip体系的网络中，

真正通信的实体是主机中的应用进程互相通信。tcp/ip的运输层使用端口号来区分不同的应用进程

UDP： 

- 无连接，（在传输前不需要建立连接，通信双方可随时发送数据）
- 支持一对一，一对多和多对一、多对多交互通信（单播、广播、多播）
- 对应用层交付的报文直接打包
- 尽最大的努力交付，也就是不可靠；不使用流量控制和拥塞控制
- 首部开销小，仅8字节

TCP：

- 面向连接
- 每一条TCP连接只能有两个端点EP，只能是一对一通信
- 面向字节流
- 可靠传输、使用流量控制和拥塞控制
- 首部最小20字节，最大60字节。

## 输入⼀个URL发生了什么

```` javascript
1. 用户输入URL，浏览器会根据用户输入的信息判断是搜索还是网址，如果是搜索内容，就将搜索内容+默认搜索引擎合成新的URL；如果用户输入的内容符合URL规则，浏览器就会根据URL协议，在这段内容上加上协议合成合法的URL

2. 用户输入完内容，按下回车键，浏览器导航栏显示loading状态，但是页面还是呈现前一个页面，这是因为新页面的响应数据还没有获得

3. 浏览器进程浏览器构建请求行信息，会通过进程间通信（IPC）将URL请求发送给网络进程
   GET /index.html HTTP1.1
   
4. 网络进程获取到URL，先去本地缓存中查找是否有缓存文件，如果有，拦截请求，直接200返回；否则，进入网络请求过程

5. 网络进程请求DNS返回域名对应的IP和端口号，如果之前DNS数据缓存服务缓存过当前域名信息，就会直接返回缓存信息；否则，发起请求获取根据域名解析出来的IP和端口号，如果没有端口号，http默认80，https默认443。如果是https请求，还需要建立TLS连接。

6. Chrome 有个机制，同一个域名同时最多只能建立 6 个TCP 连接，如果在同一个域名下同时有 10 个请求发生，那么其中 4 个请求会进入排队等待状态，直至进行中的请求完成。如果当前请求数量少于6个，会直接建立TCP连接。

7. TCP三次握手建立连接，http请求加上TCP头部——包括源端口号、目的程序端口号和用于校验数据完整性的序号，向下传输

8. 网络层在数据包上加上IP头部——包括源IP地址和目的IP地址，继续向下传输到底层

9. 底层通过物理网络传输给目的服务器主机

10. 目的服务器主机网络层接收到数据包，解析出IP头部，识别出数据部分，将解开的数据包向上传输到传输层

11. 目的服务器主机传输层获取到数据包，解析出TCP头部，识别端口，将解开的数据包向上传输到应用层

12. 应用层HTTP解析请求头和请求体，如果需要重定向，HTTP直接返回HTTP响应数据的状态code301或者302，同时在请求头的Location字段中附上重定向地址，浏览器会根据code和Location进行重定向操作；如果不是重定向，首先服务器会根据 请求头中的If-None-Match 的值来判断请求的资源是否被更新，如果没有更新，就返回304状态码，相当于告诉浏览器之前的缓存还可以使用，就不返回新数据了；否则，返回新数据，200的状态码，并且如果想要浏览器缓存数据的话，就在相应头中加入字段：
    Cache-Control:Max-age=2000
    响应数据又顺着应用层——传输层——网络层——网络层——传输层——应用层的顺序返回到网络进程
    
13. 数据传输完成，TCP四次挥手断开连接。如果，浏览器或者服务器在HTTP头部加上如下信息，TCP就一直保持连接。保持TCP连接可以省下下次需要建立连接的时间，提示资源加载速度
    Connection:Keep-Alive 
    
14. 网络进程将获取到的数据包进行解析，根据响应头中的Content-type来判断响应数据的类型，如果是字节流类型，就将该请求交给下载管理器，该导航流程结束，不再进行；如果是text/html类型，就通知浏览器进程获取到文档准备渲染

15. 浏览器进程获取到通知，根据当前页面B是否是从页面A打开的并且和页面A是否是同一个站点（根域名和协议一样就被认为是同一个站点），如果满足上述条件，就复用之前网页的进程，否则，新创建一个单独的渲染进程

16. 浏览器会发出“提交文档”的消息给渲染进程，渲染进程收到消息后，会和网络进程建立传输数据的“管道”，文档数据传输完成后，渲染进程会返回“确认提交”的消息给浏览器进程

17. 浏览器收到“确认提交”的消息后，会更新浏览器的页面状态，包括了安全状态、地址栏的 URL、前进后退的历史状态，并更新web页面，此时的web页面是空白页

18. 渲染进程对文档进行页面解析和子资源加载，HTML 通过HTM 解析器转成DOM Tree（二叉树类似结构的东西），CSS按照CSS 规则和CSS解释器转成CSSOM TREE，两个tree结合，形成render tree（不包含HTML的具体元素和元素要画的具体位置），通过Layout可以计算出每个元素具体的宽高颜色位置，结合起来，开始绘制，最后显示在屏幕中新页面显示出来
````

## https原理

### https握手过程

#### HTTPS 和 HTTP 的缓存有什么区别

## websocket和socket区别

## websocket和http区别

## http和https的区别

## 跨域

## 强缓存、协商缓存、CDN缓存

### cache-control 有哪些字段？设置 max-age: 0 跟浏览器缓不缓存有关系吗？s-max-age 的作用？

### 强缓存和协商缓存的顺序

##  Cookie 有哪些字段

## 跨域时如何处理cookie

## DNS解析会出错吗，为什么

## TCP有哪些手段保证可靠交付

## 如何应对流量劫持

## http2的多路复用

# vue3

## 响应式原理

## diff算法

## 生命周期

## 虚拟dom

## 单页面应用和多页面应用的区别及优缺点

## vuex解决了什么问题

###  Vuex 的 Mutation 和 Action 的区别

### 为什么要设计出 Mutation 和 Action 这两个东西

## 如何使用 react/vue 实现一个 message API

## 虚拟dom为什么快

## 如何设计一个组件

## 如何做到的双向绑定

## VueRouter原理

### 对于 History 路由而言，你觉得在服务端是如何做路由分发的呢

## 一个for循环中改变当前组件依赖的数据，改变一万次，会有什么效果？(批量更新和 nextTick 原理）

## vue 单项数据流

# HTML+CSS

## CSS重绘重流

# JavaScript

## 作用域链

## 原型

## 执行上下文和执行栈

## 闭包

## js事件机制

## 怎么做并发请求

## 图片懒加载

## 垃圾回收机制

## 怎么解决闭包陷阱

## async await 经过编译后和 generator 有啥联系？

# Typesctipt

## typescript有什么好处

# Webpack

## webpack打包原理

## 随着 http2 的发展，webpack 有没有更好的打包方案

## webpack 热更新原理

# Web安全

## 如何预防中间人攻击

# Node

## require的模块加载机制

## Node如何实现热更新

## 异步IO

## 垃圾回收机制

## 父进程或子进程的死亡是否会影响到对方？什么是孤儿进程？

## 消息队列

## ssr的实现原理

## 为什么客户端渲染会首屏加载过慢

## 在 Node 应用中如何利用多核心CPU的优势

## node中cluster是怎样开启多进程的，并且一个端口可以被多个进程监听吗

## node进程中怎么通信

## node可以开启多线程吗

## JWT优缺点

# 前端部署

## Docker

## Nginx

## CI/CD

### 前端如何进行多分支部署

# 前端构建

## package-lock.json 有什么作用，如果项目中没有它会怎么样，举例说明

## ESModule 既然是编译时加载，那它可以做到运行时加载吗



# 前端监控

## 性能监控

## 埋点

## 服务器监控

## 异常处理

# 前端性能优化

## 首屏渲染

## 如何提升页面加载速度，简述原理

```` javascript
合并压缩js、css⽂件
延迟加载不需要的资源
使⽤sprites合并细碎的⼩图⽚
使⽤内嵌的base64图⽚代替url
对静态资源使⽤CDN
合理配置缓存策略
服务端启⽤gzip
⽀持http2
减少阻塞脚本，使⽤async
ssr后端渲染
减少重定向
````

## 文件上传如何做断点续传

# 前端架构设计

## 一个大型项目如何分配前端开发的工作

## 如果每次要生成不一样的 ID，你怎么来设计这个系统呢

## 中后台应用如何在高重复性页面开发中通过技术方案提高开发效率

## 中后台业务

## 对前端架构的认识，如何设计出一个架构方案

# 浏览器

## 浏览器渲染过程

## 优雅降级和渐进增强

## Chrome为什么从单进程转成多进程架构

## 知道哪些进程间通信(IPC)的方式

## 线程安全

## 如果要在UI渲染之前做一些事情你会怎么办

## 分离图层做动画有什么好处

### 分离图层会发生重绘吗？(会)那既然重绘，它的好处在哪里？(不会影响其他的图层)

# 业务

## 有没有做一些提高开发效率的问题

## 技术难点

## 有没有复杂业务经验，**难点在哪里**

## 这个项目的业务背景是什么，

## 在业务上有什么比较牛逼的地方，推动了业务如何运行

## 技术实现上：这个项目的整体技术实现思路是怎样的，

## 项目中用了什么比较牛逼的技术，解决了什么比较困难的问题

# 开发技术

## vue和react谈谈区别和选型考虑

## CORS 如何设置，有哪些细节

## 图片防盗链原理

## SSR和bff的理解

## 事件循环机制，node和浏览器的事件循环机制区别

## 如何解决同步调用代码耗时太高的问题

## 对MVC、MVP、MVVM的理解

## 歌曲倍速播放的功能是怎么实现的？

## AMD 和 ESModule 有什么区别

## 设计一个适配 PC、手机和平板的项目，你有哪些布局方案

## 1px问题

## 不同浏览器兼容性问题

## 在一个大型项目中，如何定位发生内存泄露的代码

## 服务端和客户端怎么同步状态

